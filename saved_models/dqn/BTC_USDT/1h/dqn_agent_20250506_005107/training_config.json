{
    "experiment_name": "dqn_agent_20250506_005107",
    "agent_name": "dqn_agent",
    "agent_config": {
        "state_dim": [
            3722
        ],
        "action_dim": 17,
        "learning_rate": 0.001,
        "gamma": 0.99,
        "epsilon": 1.0,
        "epsilon_min": 0.01,
        "epsilon_decay": 0.995,
        "batch_size": 64,
        "memory_size": 10000,
        "update_target_freq": 100,
        "name": "dqn_agent",
        "hidden_layers": [
            64,
            64
        ],
        "activation": "relu",
        "network_type": "mlp",
        "double_dqn": true,
        "dueling": true,
        "prioritized_replay": true,
        "per_alpha": 0.6,
        "per_beta": 0.4,
        "per_beta_increment": 0.001
    },
    "env_name": "TradingEnv",
    "training_config": {
        "num_episodes": 1000,
        "max_steps_per_episode": 1000,
        "eval_frequency": 10,
        "num_eval_episodes": 5,
        "save_frequency": 100,
        "learning_starts": 1000,
        "target_update_frequency": 1000,
        "update_frequency": 4,
        "render_eval": false,
        "render_frequency": 0,
        "gamma": 0.99,
        "learning_rate": 0.001,
        "epsilon_schedule": {
            "start": 1.0,
            "end": 0.01,
            "decay_steps": 10000
        },
        "batch_size": 64
    },
    "created_at": "2025-05-06T00:51:07.878772",
    "additional_params": {
        "use_tensorboard": true,
        "save_best_only": true,
        "early_stopping": true,
        "patience": 10,
        "verbose": 1
    }
}